{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto N°1: Clasificación con método _Bag of Features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project will be evaluated in class groups. The evaluation metrics are based on your presentation and code provided in your attachments. Your solutions to the following problem should include commented source code written in Python. You can use additional modules if necessary. Analyze your results. If you discover something interesting, let us know!\n",
    "\n",
    "The past decade has seen the growing popularity of Bag of Features (BoF) approaches to many computer vision tasks, including image classification, video search, robot localization, and texture recognition. Part of the appeal is simplicity. BoF methods are based on orderless collections of quantized local image descriptors; they discard spatial information and are therefore conceptually and computationally simpler than many alternative methods [here](https://arxiv.org/pdf/1101.3354.pdf).\n",
    "\n",
    "For this project, you have to implement the Bag of Features representation for a classification problem. To accomplish this, execute the following tasks in the given order:\n",
    "\n",
    "1. Download CIFAR-10 dataset [here](https://www.kaggle.com/c/cifar-10/data). You have to select at least 4 classes to classify.\n",
    "2. For each image, compute Bag of features descriptors.\n",
    "3. Select a classifier using the BoF as input data, Options are Neural Network and KNN\n",
    "4. Evaluate the classifier using the testing set.\n",
    "5. Compute performance metrics creating a confusion matrix.\n",
    "\n",
    "For **task #3**, you have to read and implement the approach presented [here](https://arxiv.org/pdf/1101.3354.pdf), and you can look for additional information on internet. For **task #6** you should measure model performance with unseen data for this classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Importación de módulos y librerias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Selección de imagenes de entrenamiento (4 categorías)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.A Lectura del archivo de etiquetas .csv (_Comma separated values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       label\n",
      "0   1        frog\n",
      "1   2       truck\n",
      "2   3       truck\n",
      "3   4        deer\n",
      "4   5  automobile\n"
     ]
    }
   ],
   "source": [
    "# Abrimos el archivo e imprimimos la cabecera para verificar.\n",
    "filename = 'trainLabels.csv'\n",
    "labels = pd.read_csv(filename)\n",
    "print(labels.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.B Lectura de carpeta con imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista de imagenes de entrenamiento - Clase \"list\" | Tamaño: 50000\n",
      "['1.png', '10.png', '100.png', '1000.png', '10000.png']\n"
     ]
    }
   ],
   "source": [
    "# Ruta de la carpeta con los archivos\n",
    "path = 'train'\n",
    "train_set = os.listdir(path)\n",
    "print('Lista de imagenes de entrenamiento - Clase \"{}\" | Tamaño: {}'.format(type(train_set).__name__, len(train_set)))\n",
    "print(train_set[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.C Selección de imagenes en base a etiquetas elegidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del set de entrenamiento en base a categorías: 20000\n"
     ]
    }
   ],
   "source": [
    "# Lista de categorias seleccionadas\n",
    "categorias = ['cat', 'frog', 'truck', 'ship']\n",
    "\n",
    "# Filtro en base a las categorias.\n",
    "train_list = labels.loc[labels['label'].isin(categorias)]['id'].tolist()\n",
    "print('Tamaño del set de entrenamiento en base a categorías: {}'.format(len(train_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. _Bag of Features_ (Descriptor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño aproximado de descriptores por imagen: 14.8\n"
     ]
    }
   ],
   "source": [
    "# Creamos nuestra lista de vectores con los descriptores.\n",
    "des_array = []\n",
    "\n",
    "for img_item in train_list[0:20] :\n",
    "    # Creamos nuestro elemento SIFT por cada imagen\n",
    "    img  = cv2.imread(os.path.join(path, str(img_item)+'.png'))\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Calculo de los descriptores y los puntos clave (Keypoints)\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray,None)\n",
    "    # Guardamos dicho array en la lista\n",
    "    des_array.append(des)\n",
    "\n",
    "# Matriz n x 128 por cada descriptor\n",
    "des_shape = [v.shape[0] for v in des_array]\n",
    "print('Tamaño aproximado de descriptores por imagen: {}'.format(np.mean(des_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño total de descriptores: (296, 128)\n"
     ]
    }
   ],
   "source": [
    "# Organizamos todos los descriptores en una sola matriz.\n",
    "des_stack = np.vstack(des_array)\n",
    "print('Tamaño total de descriptores: {}'.format(des_stack.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clasificador por método Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.A Función para los centroides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
